# 🧠 DeepTextSummarizer

An AI-powered text summarization tool built using transformer-based deep learning models like T5 and BART. This project generates concise, context-aware summaries from long-form content such as articles, blogs, and research papers.

---

## 📌 Project Overview

**DeepTextSummarizer** leverages modern NLP techniques to automatically generate summaries from large chunks of text. It supports abstractive summarization using pre-trained models from Hugging Face and is designed to be simple, scalable, and user-friendly.

---

## 🚀 Features

- ✅ Abstractive summarization with **T5** and **BART**
- ✅ Built with Hugging Face Transformers and PyTorch
- ✅ Google Colab-friendly and interactive
- ✅ Handles raw text inputs or documents
- ✅ Customizable summary length and model choice

---

## 🧰 Tech Stack

- **Language**: Python  
- **Frameworks**: PyTorch, Hugging Face Transformers  
- **Libraries**: `transformers`, `torch`, `nltk`, `pandas`, `sklearn`

---

## 🔍 Models Used

| Model | Type | Purpose |
|-------|------|---------|
| `t5-small`, `t5-base` | Abstractive | General-purpose text summarization |
| `facebook/bart-large-cnn` | Abstractive | Fine-tuned on CNN/DailyMail summaries |

---

## 📂 Project Structure

